DONT CONFUSE: Local PC repo  vs. VM repo vs. Hadoop file system
MAKE CONNECTION
1. make sure you have files on your local repo for example: C:\Users\User1\Desktop\Karpov_DE\taxi_task
2. Run cluster DataProc (Hadoop) that contains several VM (Nodes)
3. Choose Host=VM (masterNode or DataNode) - Go to Network interface - Copy Public IPv4
4. Run CMD(Terminal) from local repo (where files are in)
5. run/connect to VM $ ssh root@84.201.186.95 (root - user\repo, numbers = Public IPv4)
6. see folders in /root/: $ ls
6.1 if needed make folders: $ mkdir /tmp/mapreduce
7. Exit from VM: $ exit
TRANSFER FILES from PC to VM
1. after making connection to transfer files from local repo to VM:
$ scp PythonFile1.py root@84.201.186.118:/tmp/mapreduce/ (or scp ./*.py root@84.201.186.118:/tmp/mapreduce/ )
2. From VM to hadoop:  connect via ssh to VM
3. change current repo: $ cd <name_folder> (go to ex folder - just $ cd)
3. $ hadoop fs -put *.py input-data (its better to type all letters by hands, not copy-past)


Next code is about how to run 'RUN.SH' file to perform mapreduce:
$ export MR_OUTPUT=/user/root/output-data
$ root@rc1c-dataproc-m-edzzo1in56jbe2vq:~/tmp/mapreducer# hadoop fs -mkdir /user/root/output-data
$ root@rc1c-dataproc-m-edzzo1in56jbe2vq:~/tmp/mapreducer# hadoop fs -rm -r $MR_OUTPUT 
RAM (!! it should be directly written - delete = -rm)
$ root@rc1c-dataproc-m-edzzo1in56jbe2vq:~/tmp/mapreducer# hadoop jar "$HADOOP_MAPRED_HOME"/hadoop-streaming.jar -Dmapred.j
ob.name='Simple streaming job reduce' -file /tmp/mapreduce/mapper.py -mapper /tmp/mapreduce/mapper.py -file /tmp/mapredu
ce/reducer.py -reducer /tmp/mapreduce/reducer.py -input /user/root/input-data -output $MR_OUTPUT 
___________________________________________
Tips: 
better to type all letters by hands, not copy-past
When its Error like No such file or directory - sometimes its just about changing slash sign to revers slash - / \ -even if prev path was written differentaly

________________________________________

PS C:\Users\Artemiy\Desktop\Karpov_DE\taxi_task> scp ./*.py root@84.201.186.95:
mapper.py                                                                             100%  266    13.6KB/s   00:00
reducer.py                                                                            100%  703    39.8KB/s   00:00
PS C:\Users\Artemiy\Desktop\Karpov_DE\taxi_task> scp ./*.sh root@84.201.186.95:
run.sh                                                                                100%  376    16.9KB/s   00:00
PS C:\Users\Artemiy\Desktop\Karpov_DE\taxi_task> ssh root@84.201.186.95
Welcome to Ubuntu 16.04.7 LTS (GNU/Linux 4.4.0-142-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage
root@rc1c-dataproc-m-edzzo1in56jbe2vq:~# hadoop fs -ls /user/root/
Found 6 items
drwxr-xr-x   - root hadoop          0 2023-02-02 16:18 /user/root/2020
-rw-r--r--   2 root hadoop         16 2023-02-02 16:00 /user/root/hello.txt
drwxr-xr-x   - root hadoop          0 2023-02-02 16:32 /user/root/input-data
-rw-r--r--   1 root hadoop          3 2023-02-02 18:12 /user/root/mapper.py
drwxr-xr-x   - root hadoop          0 2023-02-02 16:35 /user/root/tmp
-rw-r--r--   2 root hadoop  134481400 2023-02-02 16:14 /user/root/yellow_tripdata_2020-12.csv
root@rc1c-dataproc-m-edzzo1in56jbe2vq:~# hadoop fs -ls /user/root/input-data
Found 2 items
-rw-r--r--   1 root hadoop         16 2023-02-02 16:31 /user/root/input-data/hello.txt
-rw-r--r--   1 root hadoop  134481400 2023-02-02 16:32 /user/root/input-data/yellow_tripdata_2020-12.csv
root@rc1c-dataproc-m-edzzo1in56jbe2vq:~# hadoop fs –put *.py input-data/
–put: Unknown command

root@rc1c-dataproc-m-edzzo1in56jbe2vq:~# hadoop fs -put *.py /root/input-data
put: `/root/input-data': No such file or directory
root@rc1c-dataproc-m-edzzo1in56jbe2vq:~# hadoop fs -put *.py /input-data
put: `/input-data': No such file or directory
root@rc1c-dataproc-m-edzzo1in56jbe2vq:~# hadoop fs -put *.py /user/root/input-data
root@rc1c-dataproc-m-edzzo1in56jbe2vq:~# hadoop fs -ls /user/root/input-data
Found 4 items
-rw-r--r--   1 root hadoop         16 2023-02-02 16:31 /user/root/input-data/hello.txt
-rw-r--r--   1 root hadoop        266 2023-02-02 20:08 /user/root/input-data/mapper.py
-rw-r--r--   1 root hadoop        703 2023-02-02 20:08 /user/root/input-data/reducer.py
-rw-r--r--   1 root hadoop  134481400 2023-02-02 16:32 /user/root/input-data/yellow_tripdata_2020-12.csv
root@rc1c-dataproc-m-edzzo1in56jbe2vq:~# hadoop fs -put *.sh /user/root/input-data
root@rc1c-dataproc-m-edzzo1in56jbe2vq:~# hadoop fs -ls /user/root/input-data
Found 5 items
-rw-r--r--   1 root hadoop         16 2023-02-02 16:31 /user/root/input-data/hello.txt
-rw-r--r--   1 root hadoop        266 2023-02-02 20:08 /user/root/input-data/mapper.py
-rw-r--r--   1 root hadoop        703 2023-02-02 20:08 /user/root/input-data/reducer.py
-rw-r--r--   1 root hadoop        376 2023-02-02 20:09 /user/root/input-data/run.sh
-rw-r--r--   1 root hadoop  134481400 2023-02-02 16:32 /user/root/input-data/yellow_tripdata_2020-12.csv
root@rc1c-dataproc-m-edzzo1in56jbe2vq:~#