Hive is preinstalled when Cluster DataProc was created (it should be \/ check the box)
1. Run cluster
2. Connect to VM on cluster (choose VM f.e. MasterNode), get Public IP, $ ssh root@<Public IP>
3. run hive on VM: $ hive
4. Create Database in hive: hive> $ create database yellow_taxi location '/user/root/yellow_taxi_db'; (RAM: dont forget ";")



___________________
Not Tested
___________________
create database yellow_taxi location 's3a://bucketasokolov/' ; --'/user/root' ; --'s3a://karpov-data/';
drop database yellow_taxi2 CASCADE;
drop table yellow_taxi.yellow_taxi_trip_tab;
drop table yellow_taxi.yellow_taxi_trip_records
;
select count(*) over(), * from yellow_taxi.yellow_taxi_trip_records
;
create external table  yellow_taxi.yellow_taxi_trip_records
(
vendorid int
, tpep_pickup_datetime timestamp
, tpep_dropoff_datetime timestamp
, passenger_count int
, trip_distance double 
, pulocationid int
, dolocationid int
, ratecodeid int
, store_and_fwd_flag varchar(8)
, payment_type int
, fare_amount double
, extra double
, mta_tax double 
, improvement_surcharge double
, tip_amount double
, tolls_amount double 
, total_amount double
, congestion_surcharge double
, airport_fee double
)
partitioned by (dt date)
row format delimited
fields terminated by ','
stored as parquet
--location '/user/root/input-data'
location 's3a://bucketasokolov/' --/yellow-taxi-2020'
;

create table  yellow_taxi.VendorID_xref
(
 id int
 , name string
)
stored as parquet;

create table  yellow_taxi.RateCodeID_xref
(
 id int
 , name string
)
stored as parquet;

create table  yellow_taxi.Payment_type _xref
(
 id int
 , name string
)
stored as parquet;







